{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Getting Data into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"You donâ€™t understand anything until you learn it more than one way\". ~ Marvin Minsky\n",
    "\n",
    "> \"Wear your learning, like a watch, in a private pocket: and do not pull it out and strike it, merely to show that you have one.\" ~ Lord Chesterfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sankey](http://visualoop.com/media/2015/05/1.jpg)\n",
    "\n",
    "**Source:** [Vallerio Pellegrini](https://www.behance.net/valeriopellegrini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "\n",
    "1. Getting Data Into Python\n",
    "2. Text\n",
    "3. Excel\n",
    "4. HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Data into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all the data](http://blogs.ubc.ca/coetoolbox/files/2014/03/meme-data-data-everywhere.png)\n",
    "\n",
    "When working with data in Python you will encounter datasets coming in all shapes and formats, so it is crucial to understand how to deal with them in order to work with data. We will be covering the following 4 formats in this section (yes, there are only 4 here ðŸ˜):\n",
    "\n",
    "- CSV --> Comma Separated Values --> `pd.read_csv(file, sep=',')`\n",
    "- TSV --> Tab Separated Values --> `pd.read_csv(file, sep=' ')`\n",
    "- Excel --> Microsoft Excel format (.xlsx) --> `pd.read_excel()`\n",
    "- JSON --> JavaScript Object Notation --> `pd.read_json()`\n",
    "- HTML --> Hypertext Markup Language --> `pd.read_html()`\n",
    "\n",
    "For this part of the lesson, we will be using some real world datasets that you can find more info about (e.g. how to download them) in datasets directory one level above this one. Please download them and add them to the datasets directory for this course, or whichever directory you'd like to use.\n",
    "\n",
    "![want the data](http://blog.charitydynamics.com/wp-content/uploads/2015/05/data-cat_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text files are extremely common among organisations, and hence, they will form a big part of the files you will encounter in your daily work. More specifically, files with a format such as **Comma** and **Tab** separated values, along with other text files that use different delimiters, might amount to half (if not more) of the files that you will see at work.\n",
    "\n",
    "These two formats, **Comma** and **Tab**, are still only a text file but they are very useful for saving and distributing small and large datasets in a tabular way. You can identify both kinds of files by looking at the suffix part in the name of a file, comma separated values will end in `.csv` while tab separated values will end with `.tsv`.\n",
    "\n",
    "What makes these two files so similar is that they are both separated by something called delimiter. If you have a CSV or TSV file, try opening them in a plain text editor application (notepad for windows users and ) and notice what comes up.\n",
    "\n",
    "![csv](pictures/csv_file.png)\n",
    "\n",
    "Notice that in the example above, every value is separated by a comma and although the column headers can be found at the very top of the file (this is common practice) sometimes you might not even have them available. When we save files as TSV, CSV or with any other kind of delimiter, words with spaces in them will be wrapped around quotation marks to differentiate the spaces from the delimiter (which might be a space itself) in the data.\n",
    "\n",
    "Lastly, let's talk about how pandas handles these types of files. To read text files into a DataFrame with pandas we can use the function `pd.read_csv()` or `pd.read_table()`. These functions, at the time of writing, have over 50 parameters that allow us to customise different specification on how we would like to read in the data. One of the most important parameters is the `sep=`, which allows us to define the delimiter we would like to read in the data with. `\",\"` is the default for `pd.read_csv()` and `\"\\t\"` is the default for `pd.read_table()`.\n",
    "\n",
    "The following parameters are some of the most useful ones not only for reading in text files, but also to tackle, and save time with, many of the operations you might need to perform after reading the data. Please visit the pandas documentation for more info.\n",
    "\n",
    "- `header=` --> tells pandas whether the first column contains the headers of the dataframe or not.\n",
    "- `names=[list, of, column, names]` --> allows us to explicitly name the columns of a dataframe in the order in which they are read.\n",
    "- `parse_dates=` --> gives pandas permision to look for what might look like date data and it will assign it the appropriate date data type format.\n",
    "- `index_col=` --> allows us to assign a specific column as the index of our dataframe.\n",
    "- `skiprows=\\[1, 2, 3, 4\\]` --> tells pandas which rows we want to skip.\n",
    "- `na_values=` --> takes in a list of values that might be missing and assigns them the NaN value, which stands for not a number.\n",
    "- `encoding=` --> data might coming in from a variety of sources could have different encodings, e.g. 'UTF-8' or 'ASCII', and this parameter helps us specify which one we need for our data.\n",
    "- `nrows=4` --> how many rows do you want to read from a file. Very useful tool for examining the first few lines of large files.\n",
    "\n",
    "Let's use the Air Quality Monitoring Dataset and first read in the CSV file and then the TSV one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is the name of the file as a string or the path to the folder where the data lives followed by the name of the file and its extension. Once you load the dataset and assign it to a variable, you can see its first 5 rows plus the column names using the method `.head()`, or the method `.tail()` for the last 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first argument is the folder where the data lives and the name of the data\n",
    "\n",
    "df_csv = pd.read_csv('C:/Users/monch.mercader/Python/Data_Analytics/Module 1/datasets/files/seek_australia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail &amp; Consumer Products</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Frontline Executive Retail Sydney</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Have you had 10 years experience in fresh pro...</td>\n",
       "      <td>Store Manager - Fresh Produce</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:13:45Z</td>\n",
       "      <td>$100k Base + Super + Benefits</td>\n",
       "      <td>North Shore &amp; Northern Beaches</td>\n",
       "      <td>https://www.seek.com.au/job/35989382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Government &amp; Defence</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Powerlink</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>The Opportunity: The Client Solution Analyst ...</td>\n",
       "      <td>Client Solution Analyst</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:40Z</td>\n",
       "      <td>Excellent remuneration packages</td>\n",
       "      <td>Northern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Richard Jay Laundry</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>An innovative business development role for a...</td>\n",
       "      <td>Service Technician / Installer - NSW</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-15T23:04:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parramatta &amp; Western Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35989270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Adaptalift Hyster</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>About the role: We are seeking an Automotive W...</td>\n",
       "      <td>Workshop Technician I Material Handling Equipment</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T03:15:17Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside &amp; South Eastern Suburbs</td>\n",
       "      <td>https://www.seek.com.au/job/35993203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Bakers Delight G&amp;M</td>\n",
       "      <td>AU</td>\n",
       "      <td>seek</td>\n",
       "      <td>Ã‚Â Early starts and weekend shifts. No experie...</td>\n",
       "      <td>APPRENTICESHIP JUNIOR BAKER</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2018-04-16T01:26:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.seek.com.au/job/35991578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category       city                       company_name  \\\n",
       "0  Retail & Consumer Products     Sydney  Frontline Executive Retail Sydney   \n",
       "1        Government & Defence   Brisbane                          Powerlink   \n",
       "2           Trades & Services     Sydney                Richard Jay Laundry   \n",
       "3           Trades & Services  Melbourne                  Adaptalift Hyster   \n",
       "4           Trades & Services   Adelaide                 Bakers Delight G&M   \n",
       "\n",
       "  geo job_board                                    job_description  \\\n",
       "0  AU      seek   Have you had 10 years experience in fresh pro...   \n",
       "1  AU      seek   The Opportunity: The Client Solution Analyst ...   \n",
       "2  AU      seek   An innovative business development role for a...   \n",
       "3  AU      seek  About the role: We are seeking an Automotive W...   \n",
       "4  AU      seek   Ã‚Â Early starts and weekend shifts. No experie...   \n",
       "\n",
       "                                           job_title   job_type  \\\n",
       "0                      Store Manager - Fresh Produce  Full Time   \n",
       "1                            Client Solution Analyst  Full Time   \n",
       "2               Service Technician / Installer - NSW  Full Time   \n",
       "3  Workshop Technician I Material Handling Equipment  Full Time   \n",
       "4                        APPRENTICESHIP JUNIOR BAKER  Full Time   \n",
       "\n",
       "              post_date                   salary_offered  \\\n",
       "0  2018-04-15T23:13:45Z    $100k Base + Super + Benefits   \n",
       "1  2018-04-15T23:04:40Z  Excellent remuneration packages   \n",
       "2  2018-04-15T23:04:31Z                              NaN   \n",
       "3  2018-04-16T03:15:17Z                              NaN   \n",
       "4  2018-04-16T01:26:50Z                              NaN   \n",
       "\n",
       "                             state                                   url  \n",
       "0   North Shore & Northern Beaches  https://www.seek.com.au/job/35989382  \n",
       "1                 Northern Suburbs  https://www.seek.com.au/job/35989272  \n",
       "2     Parramatta & Western Suburbs  https://www.seek.com.au/job/35989270  \n",
       "3  Bayside & South Eastern Suburbs  https://www.seek.com.au/job/35993203  \n",
       "4                              NaN  https://www.seek.com.au/job/35991578  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the look and feel of our file resembles that of a spreadsheet in Excel or Google Sheets.\n",
    "\n",
    "To read in Tab Separated Value files, all we need to do is to pass in the `sep=` argument to our `pd.read_csv()` function and provide pandas with the specific delimiter the data is split by. For tab separated values we use `\\t`, but there are many other delimiters one can choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GPS</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3_1hr</th>\n",
       "      <th>O3_4hr</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>AQI_CO</th>\n",
       "      <th>AQI_NO2</th>\n",
       "      <th>AQI_O3_1hr</th>\n",
       "      <th>AQI_O3_4hr</th>\n",
       "      <th>AQI_PM10</th>\n",
       "      <th>AQI_PM2.5</th>\n",
       "      <th>AQI_Site</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Florey</td>\n",
       "      <td>(-35.220606, 149.043539)</td>\n",
       "      <td>11/11/2020 04:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.95</td>\n",
       "      <td>5.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 November 2020</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monash</td>\n",
       "      <td>(-35.418302, 149.094018)</td>\n",
       "      <td>11/11/2020 04:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.99</td>\n",
       "      <td>5.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 November 2020</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Civic</td>\n",
       "      <td>(-35.285307, 149.131579)</td>\n",
       "      <td>11/11/2020 04:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.35</td>\n",
       "      <td>5.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11 November 2020</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Florey</td>\n",
       "      <td>(-35.220606, 149.043539)</td>\n",
       "      <td>11/11/2020 05:00:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11 November 2020</td>\n",
       "      <td>17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monash</td>\n",
       "      <td>(-35.418302, 149.094018)</td>\n",
       "      <td>11/11/2020 05:00:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.41</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11 November 2020</td>\n",
       "      <td>17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name                       GPS                DateTime  NO2  O3_1hr  \\\n",
       "0  Florey  (-35.220606, 149.043539)  11/11/2020 04:00:00 PM  NaN     NaN   \n",
       "1  Monash  (-35.418302, 149.094018)  11/11/2020 04:00:00 PM  NaN     NaN   \n",
       "2   Civic  (-35.285307, 149.131579)  11/11/2020 04:00:00 PM  NaN     NaN   \n",
       "3  Florey  (-35.220606, 149.043539)  11/11/2020 05:00:00 PM  0.0   0.035   \n",
       "4  Monash  (-35.418302, 149.094018)  11/11/2020 05:00:00 PM  0.0   0.038   \n",
       "\n",
       "   O3_4hr   CO   PM10  PM2.5  AQI_CO  AQI_NO2  AQI_O3_1hr  AQI_O3_4hr  \\\n",
       "0     NaN  NaN  11.95   5.55     NaN      NaN         NaN         NaN   \n",
       "1     NaN  NaN  12.99   5.42     NaN      NaN         NaN         NaN   \n",
       "2     NaN  NaN  14.35   5.76     NaN      NaN         NaN         NaN   \n",
       "3   0.037  0.0  12.50   5.55     0.0      0.0        35.0        47.0   \n",
       "4   0.037  0.0  13.41   5.40     0.0      0.0        38.0        46.0   \n",
       "\n",
       "   AQI_PM10  AQI_PM2.5  AQI_Site              Date      Time  \n",
       "0      23.0       22.0       NaN  11 November 2020  16:00:00  \n",
       "1      25.0       21.0       NaN  11 November 2020  16:00:00  \n",
       "2      28.0       23.0      28.0  11 November 2020  16:00:00  \n",
       "3      25.0       22.0      47.0  11 November 2020  17:00:00  \n",
       "4      26.0       21.0      46.0  11 November 2020  17:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# air quality data in Australia\n",
    "df_tsv = pd.read_csv('C:/Users/monch.mercader/Python/Data_Analytics/Module 1/datasets/files/Air_Quality_Monitoring_Data.tsv', sep='\\t')\n",
    "df_tsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another method in pandas that uses the Tab Separated Values delimiter `\"\\t\"` as its default delimiter, and that is the `pd.read_table()` method. You should use whichever you prefer, especially since most of the options in one can be found in the other. This means that by indicating the `sep=','` with a comma, you can obtain the same result as with the `pd.read_csv()` and read in Comma Separated Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LicenceNumber,LicenceCode,LicenceType,LicenseeOrg,liccount,lictotal,Licensees,TradingNames,Address,Suburb,State,Postcode,Dateexpiry,Dateissued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17721736,SEMP,\"1A - patrol, guard, watch or pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17723761,SEMP,1C - act as a crowd controller,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18901138,EA,Licensed Employment Agent,Company,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17723543,SEMP,\"1A - patrol, guard, watch or pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18402498,RA,Licensed Real Estate Agents,Indivi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LicenceNumber,LicenceCode,LicenceType,LicenseeOrg,liccount,lictotal,Licensees,TradingNames,Address,Suburb,State,Postcode,Dateexpiry,Dateissued\n",
       "0  17721736,SEMP,\"1A - patrol, guard, watch or pr...                                                                                            \n",
       "1  17723761,SEMP,1C - act as a crowd controller,I...                                                                                            \n",
       "2  18901138,EA,Licensed Employment Agent,Company,...                                                                                            \n",
       "3  17723543,SEMP,\"1A - patrol, guard, watch or pr...                                                                                            \n",
       "4  18402498,RA,Licensed Real Estate Agents,Indivi...                                                                                            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupational licenses data\n",
    "df_table = pd.read_table('C:/Users/monch.mercader/Python/Data_Analytics/Module 1/datasets/files/occupational_licences.csv')\n",
    "df_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know a dataset has dates in it we can also convert it to the datetime format provided by pandas as we read in the data. We can do this by putting the names of the columns that have dates in the `parse_dates=` parameter of our `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>ACCIDENT_NO</th>\n",
       "      <th>ABS_CODE</th>\n",
       "      <th>ACCIDENT_STATUS</th>\n",
       "      <th>ACCIDENT_DATE</th>\n",
       "      <th>ACCIDENT_TIME</th>\n",
       "      <th>ALCOHOLTIME</th>\n",
       "      <th>ACCIDENT_TYPE</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DCA_CODE</th>\n",
       "      <th>...</th>\n",
       "      <th>DEG_URBAN_ALL</th>\n",
       "      <th>LGA_NAME_ALL</th>\n",
       "      <th>REGION_NAME_ALL</th>\n",
       "      <th>SRNS</th>\n",
       "      <th>SRNS_ALL</th>\n",
       "      <th>RMA</th>\n",
       "      <th>RMA_ALL</th>\n",
       "      <th>DIVIDED</th>\n",
       "      <th>DIVIDED_ALL</th>\n",
       "      <th>STAT_DIV_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3401744</td>\n",
       "      <td>T20130013732</td>\n",
       "      <td>ABS to receive accident</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>18.30.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Struck Pedestrian</td>\n",
       "      <td>Monday</td>\n",
       "      <td>PED NEAR SIDE. PED HIT BY VEHICLE FROM THE RIGHT.</td>\n",
       "      <td>...</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>MELBOURNE</td>\n",
       "      <td>METROPOLITAN NORTH WEST REGION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Undivided</td>\n",
       "      <td>Undiv</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3401745</td>\n",
       "      <td>T20130013736</td>\n",
       "      <td>ABS to receive accident</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>16.40.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Collision with vehicle</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>PARKED VEHICLES ONLY</td>\n",
       "      <td>...</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>WHITEHORSE</td>\n",
       "      <td>METROPOLITAN SOUTH EAST REGION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arterial Other</td>\n",
       "      <td>Arterial Other,Local Road</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Div,Undiv</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3401746</td>\n",
       "      <td>T20130013737</td>\n",
       "      <td>ABS to receive accident</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>13.15.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Collision with a fixed object</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>RIGHT OFF CARRIAGEWAY INTO OBJECT/PARKED VEHICLE</td>\n",
       "      <td>...</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>BRIMBANK</td>\n",
       "      <td>METROPOLITAN NORTH WEST REGION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Undivided</td>\n",
       "      <td>Undiv</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3401747</td>\n",
       "      <td>T20130013738</td>\n",
       "      <td>ABS to receive accident</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>16.45.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Collision with a fixed object</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>RIGHT OFF CARRIAGEWAY INTO OBJECT/PARKED VEHICLE</td>\n",
       "      <td>...</td>\n",
       "      <td>RURAL_VICTORIA</td>\n",
       "      <td>MITCHELL</td>\n",
       "      <td>NORTHERN REGION</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Div</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3401748</td>\n",
       "      <td>T20130013739</td>\n",
       "      <td>ABS to receive accident</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>15.48.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Collision with vehicle</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>U TURN</td>\n",
       "      <td>...</td>\n",
       "      <td>MELBOURNE_CBD,MELB_URBAN</td>\n",
       "      <td>MELBOURNE</td>\n",
       "      <td>METROPOLITAN NORTH WEST REGION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Undivided</td>\n",
       "      <td>Undiv</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID   ACCIDENT_NO                 ABS_CODE ACCIDENT_STATUS  \\\n",
       "0   3401744  T20130013732  ABS to receive accident        Finished   \n",
       "1   3401745  T20130013736  ABS to receive accident        Finished   \n",
       "2   3401746  T20130013737  ABS to receive accident        Finished   \n",
       "3   3401747  T20130013738  ABS to receive accident        Finished   \n",
       "4   3401748  T20130013739  ABS to receive accident        Finished   \n",
       "\n",
       "  ACCIDENT_DATE ACCIDENT_TIME ALCOHOLTIME                  ACCIDENT_TYPE  \\\n",
       "0    2013-01-07      18.30.00         Yes              Struck Pedestrian   \n",
       "1    2013-02-07      16.40.00          No         Collision with vehicle   \n",
       "2    2013-02-07      13.15.00          No  Collision with a fixed object   \n",
       "3    2013-02-07      16.45.00          No  Collision with a fixed object   \n",
       "4    2013-02-07      15.48.00          No         Collision with vehicle   \n",
       "\n",
       "  DAY_OF_WEEK                                           DCA_CODE  ...  \\\n",
       "0      Monday  PED NEAR SIDE. PED HIT BY VEHICLE FROM THE RIGHT.  ...   \n",
       "1     Tuesday                               PARKED VEHICLES ONLY  ...   \n",
       "2     Tuesday   RIGHT OFF CARRIAGEWAY INTO OBJECT/PARKED VEHICLE  ...   \n",
       "3     Tuesday   RIGHT OFF CARRIAGEWAY INTO OBJECT/PARKED VEHICLE  ...   \n",
       "4     Tuesday                                             U TURN  ...   \n",
       "\n",
       "              DEG_URBAN_ALL LGA_NAME_ALL                 REGION_NAME_ALL SRNS  \\\n",
       "0                MELB_URBAN    MELBOURNE  METROPOLITAN NORTH WEST REGION  NaN   \n",
       "1                MELB_URBAN   WHITEHORSE  METROPOLITAN SOUTH EAST REGION  NaN   \n",
       "2                MELB_URBAN     BRIMBANK  METROPOLITAN NORTH WEST REGION  NaN   \n",
       "3            RURAL_VICTORIA     MITCHELL                 NORTHERN REGION    M   \n",
       "4  MELBOURNE_CBD,MELB_URBAN    MELBOURNE  METROPOLITAN NORTH WEST REGION  NaN   \n",
       "\n",
       "  SRNS_ALL             RMA                    RMA_ALL    DIVIDED  DIVIDED_ALL  \\\n",
       "0      NaN      Local Road                 Local Road  Undivided        Undiv   \n",
       "1      NaN  Arterial Other  Arterial Other,Local Road    Divided    Div,Undiv   \n",
       "2      NaN      Local Road                 Local Road  Undivided        Undiv   \n",
       "3        M         Freeway                    Freeway    Divided          Div   \n",
       "4      NaN      Local Road                 Local Road  Undivided        Undiv   \n",
       "\n",
       "   STAT_DIV_NAME  \n",
       "0          Metro  \n",
       "1          Metro  \n",
       "2          Metro  \n",
       "3        Country  \n",
       "4          Metro  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first argument is the folder where the data lives and the name of the data\n",
    "\n",
    "df_csv = pd.read_csv('C:/Users/monch.mercader/Python/Data_Analytics/Module 1/datasets/files/Crashes_Last_Five_Years.csv', parse_dates=['ACCIDENT_DATE', 'ACCIDENT_TIME'])\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract additional information from our date variables with some attributes that you can find in the [dates section of pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2013\n",
       "1    2013\n",
       "2    2013\n",
       "3    2013\n",
       "4    2013\n",
       "Name: ACCIDENT_DATE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are accessing the year\n",
    "df_csv['ACCIDENT_DATE'].dt.year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74903    1\n",
       "74904    1\n",
       "74905    7\n",
       "74906    1\n",
       "74907    1\n",
       "Name: ACCIDENT_DATE, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are accessing the month\n",
    "df_csv['ACCIDENT_DATE'].dt.month.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Go to any of the websites below, download a dataset of your choosing and read it into memory with `pd.read_csv()`. Use at least one additional argument to read in your file.\n",
    "\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
    "- [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "- [Data.GOV](Data.gov)\n",
    "- [FiveThirtyEight](https://data.fivethirtyeight.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102046.0</td>\n",
       "      <td>102560.0</td>\n",
       "      <td>103159.0</td>\n",
       "      <td>103774.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104872.0</td>\n",
       "      <td>105366.0</td>\n",
       "      <td>105845.0</td>\n",
       "      <td>106314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>8996973.0</td>\n",
       "      <td>9169410.0</td>\n",
       "      <td>9351441.0</td>\n",
       "      <td>9543205.0</td>\n",
       "      <td>9744781.0</td>\n",
       "      <td>9956320.0</td>\n",
       "      <td>10174836.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29185507.0</td>\n",
       "      <td>30117413.0</td>\n",
       "      <td>31161376.0</td>\n",
       "      <td>32269589.0</td>\n",
       "      <td>33370794.0</td>\n",
       "      <td>34413603.0</td>\n",
       "      <td>35383128.0</td>\n",
       "      <td>36296400.0</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>38041754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>5454933.0</td>\n",
       "      <td>5531472.0</td>\n",
       "      <td>5608539.0</td>\n",
       "      <td>5679458.0</td>\n",
       "      <td>5735044.0</td>\n",
       "      <td>5770570.0</td>\n",
       "      <td>5781214.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23356246.0</td>\n",
       "      <td>24220661.0</td>\n",
       "      <td>25107931.0</td>\n",
       "      <td>26015780.0</td>\n",
       "      <td>26941779.0</td>\n",
       "      <td>27884381.0</td>\n",
       "      <td>28842484.0</td>\n",
       "      <td>29816748.0</td>\n",
       "      <td>30809762.0</td>\n",
       "      <td>31825295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "      <td>2866376.0</td>\n",
       "      <td>2854191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>19647.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83747.0</td>\n",
       "      <td>82427.0</td>\n",
       "      <td>80774.0</td>\n",
       "      <td>79213.0</td>\n",
       "      <td>78011.0</td>\n",
       "      <td>77297.0</td>\n",
       "      <td>77001.0</td>\n",
       "      <td>77006.0</td>\n",
       "      <td>77142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>947000.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>994000.0</td>\n",
       "      <td>1022000.0</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>1078000.0</td>\n",
       "      <td>1106000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1775680.0</td>\n",
       "      <td>1791000.0</td>\n",
       "      <td>1807106.0</td>\n",
       "      <td>1818117.0</td>\n",
       "      <td>1812771.0</td>\n",
       "      <td>1788196.0</td>\n",
       "      <td>1777557.0</td>\n",
       "      <td>1791003.0</td>\n",
       "      <td>1797085.0</td>\n",
       "      <td>1794248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>5315355.0</td>\n",
       "      <td>5393036.0</td>\n",
       "      <td>5473671.0</td>\n",
       "      <td>5556766.0</td>\n",
       "      <td>5641597.0</td>\n",
       "      <td>5727751.0</td>\n",
       "      <td>5816247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23154855.0</td>\n",
       "      <td>23807588.0</td>\n",
       "      <td>24473178.0</td>\n",
       "      <td>25147109.0</td>\n",
       "      <td>25823485.0</td>\n",
       "      <td>26497889.0</td>\n",
       "      <td>27168210.0</td>\n",
       "      <td>27834821.0</td>\n",
       "      <td>28498687.0</td>\n",
       "      <td>29161922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>17099840.0</td>\n",
       "      <td>17524533.0</td>\n",
       "      <td>17965725.0</td>\n",
       "      <td>18423161.0</td>\n",
       "      <td>18896307.0</td>\n",
       "      <td>19384841.0</td>\n",
       "      <td>19888250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51216964.0</td>\n",
       "      <td>52004172.0</td>\n",
       "      <td>52834005.0</td>\n",
       "      <td>53689236.0</td>\n",
       "      <td>54545991.0</td>\n",
       "      <td>55386367.0</td>\n",
       "      <td>56203654.0</td>\n",
       "      <td>57000451.0</td>\n",
       "      <td>57779622.0</td>\n",
       "      <td>58558270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3070776.0</td>\n",
       "      <td>3164329.0</td>\n",
       "      <td>3260650.0</td>\n",
       "      <td>3360104.0</td>\n",
       "      <td>3463213.0</td>\n",
       "      <td>3570464.0</td>\n",
       "      <td>3681955.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13605984.0</td>\n",
       "      <td>14023193.0</td>\n",
       "      <td>14465121.0</td>\n",
       "      <td>14926504.0</td>\n",
       "      <td>15399753.0</td>\n",
       "      <td>15879361.0</td>\n",
       "      <td>16363507.0</td>\n",
       "      <td>16853688.0</td>\n",
       "      <td>17351822.0</td>\n",
       "      <td>17861030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3776681.0</td>\n",
       "      <td>3905034.0</td>\n",
       "      <td>4039201.0</td>\n",
       "      <td>4178726.0</td>\n",
       "      <td>4322861.0</td>\n",
       "      <td>4471177.0</td>\n",
       "      <td>4623351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12697723.0</td>\n",
       "      <td>12894316.0</td>\n",
       "      <td>13115131.0</td>\n",
       "      <td>13350356.0</td>\n",
       "      <td>13586681.0</td>\n",
       "      <td>13814629.0</td>\n",
       "      <td>14030390.0</td>\n",
       "      <td>14236745.0</td>\n",
       "      <td>14439018.0</td>\n",
       "      <td>14645468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code     Indicator Name        1960        1961  \\\n",
       "0           Aruba          ABW  Population, total     54211.0     55438.0   \n",
       "1     Afghanistan          AFG  Population, total   8996973.0   9169410.0   \n",
       "2          Angola          AGO  Population, total   5454933.0   5531472.0   \n",
       "3         Albania          ALB  Population, total   1608800.0   1659800.0   \n",
       "4         Andorra          AND  Population, total     13411.0     14375.0   \n",
       "..            ...          ...                ...         ...         ...   \n",
       "259        Kosovo          XKX  Population, total    947000.0    966000.0   \n",
       "260   Yemen, Rep.          YEM  Population, total   5315355.0   5393036.0   \n",
       "261  South Africa          ZAF  Population, total  17099840.0  17524533.0   \n",
       "262        Zambia          ZMB  Population, total   3070776.0   3164329.0   \n",
       "263      Zimbabwe          ZWE  Population, total   3776681.0   3905034.0   \n",
       "\n",
       "           1962        1963        1964        1965        1966  ...  \\\n",
       "0       56225.0     56695.0     57032.0     57360.0     57715.0  ...   \n",
       "1     9351441.0   9543205.0   9744781.0   9956320.0  10174836.0  ...   \n",
       "2     5608539.0   5679458.0   5735044.0   5770570.0   5781214.0  ...   \n",
       "3     1711319.0   1762621.0   1814135.0   1864791.0   1914573.0  ...   \n",
       "4       15370.0     16412.0     17469.0     18549.0     19647.0  ...   \n",
       "..          ...         ...         ...         ...         ...  ...   \n",
       "259    994000.0   1022000.0   1050000.0   1078000.0   1106000.0  ...   \n",
       "260   5473671.0   5556766.0   5641597.0   5727751.0   5816247.0  ...   \n",
       "261  17965725.0  18423161.0  18896307.0  19384841.0  19888250.0  ...   \n",
       "262   3260650.0   3360104.0   3463213.0   3570464.0   3681955.0  ...   \n",
       "263   4039201.0   4178726.0   4322861.0   4471177.0   4623351.0  ...   \n",
       "\n",
       "           2010        2011        2012        2013        2014        2015  \\\n",
       "0      101669.0    102046.0    102560.0    103159.0    103774.0    104341.0   \n",
       "1    29185507.0  30117413.0  31161376.0  32269589.0  33370794.0  34413603.0   \n",
       "2    23356246.0  24220661.0  25107931.0  26015780.0  26941779.0  27884381.0   \n",
       "3     2913021.0   2905195.0   2900401.0   2895092.0   2889104.0   2880703.0   \n",
       "4       84449.0     83747.0     82427.0     80774.0     79213.0     78011.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "259   1775680.0   1791000.0   1807106.0   1818117.0   1812771.0   1788196.0   \n",
       "260  23154855.0  23807588.0  24473178.0  25147109.0  25823485.0  26497889.0   \n",
       "261  51216964.0  52004172.0  52834005.0  53689236.0  54545991.0  55386367.0   \n",
       "262  13605984.0  14023193.0  14465121.0  14926504.0  15399753.0  15879361.0   \n",
       "263  12697723.0  12894316.0  13115131.0  13350356.0  13586681.0  13814629.0   \n",
       "\n",
       "           2016        2017        2018        2019  \n",
       "0      104872.0    105366.0    105845.0    106314.0  \n",
       "1    35383128.0  36296400.0  37172386.0  38041754.0  \n",
       "2    28842484.0  29816748.0  30809762.0  31825295.0  \n",
       "3     2876101.0   2873457.0   2866376.0   2854191.0  \n",
       "4       77297.0     77001.0     77006.0     77142.0  \n",
       "..          ...         ...         ...         ...  \n",
       "259   1777557.0   1791003.0   1797085.0   1794248.0  \n",
       "260  27168210.0  27834821.0  28498687.0  29161922.0  \n",
       "261  56203654.0  57000451.0  57779622.0  58558270.0  \n",
       "262  16363507.0  16853688.0  17351822.0  17861030.0  \n",
       "263  14030390.0  14236745.0  14439018.0  14645468.0  \n",
       "\n",
       "[264 rows x 63 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../Module 1/datasets/files/WorldPopulation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceID</th>\n",
       "      <th>branch</th>\n",
       "      <th>city</th>\n",
       "      <th>cust_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>type</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment</th>\n",
       "      <th>cost</th>\n",
       "      <th>gross income</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>894-41-5205</td>\n",
       "      <td>C</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Food and beverages</td>\n",
       "      <td>43.18</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>19:39:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>345.44</td>\n",
       "      <td>17.2720</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>895-03-6665</td>\n",
       "      <td>B</td>\n",
       "      <td>Ismailia</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Fashion accessories</td>\n",
       "      <td>36.51</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-02-16</td>\n",
       "      <td>10:52:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>328.59</td>\n",
       "      <td>16.4295</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>895-66-0685</td>\n",
       "      <td>B</td>\n",
       "      <td>Ismailia</td>\n",
       "      <td>Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>Food and beverages</td>\n",
       "      <td>18.08</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>19:46:00</td>\n",
       "      <td>eWallet</td>\n",
       "      <td>54.24</td>\n",
       "      <td>2.7120</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>896-34-0956</td>\n",
       "      <td>A</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Fashion accessories</td>\n",
       "      <td>21.32</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>12:43:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>21.32</td>\n",
       "      <td>1.0660</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>898-04-2717</td>\n",
       "      <td>A</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Fashion accessories</td>\n",
       "      <td>76.40</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>15:49:00</td>\n",
       "      <td>eWallet</td>\n",
       "      <td>687.60</td>\n",
       "      <td>34.3800</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       invoiceID branch        city cust_type  gender                 type  \\\n",
       "995  894-41-5205      C  Alexandria    Normal  Female   Food and beverages   \n",
       "996  895-03-6665      B    Ismailia    Normal  Female  Fashion accessories   \n",
       "997  895-66-0685      B    Ismailia    Member    Male   Food and beverages   \n",
       "998  896-34-0956      A       Cairo    Normal    Male  Fashion accessories   \n",
       "999  898-04-2717      A       Cairo    Normal    Male  Fashion accessories   \n",
       "\n",
       "     unit_price  quantity       date      time      payment    cost  \\\n",
       "995       43.18         8 2019-01-19  19:39:00  Credit card  345.44   \n",
       "996       36.51         9 2019-02-16  10:52:00         Cash  328.59   \n",
       "997       18.08         3 2019-03-05  19:46:00      eWallet   54.24   \n",
       "998       21.32         1 2019-01-26  12:43:00         Cash   21.32   \n",
       "999       76.40         9 2019-03-19  15:49:00      eWallet  687.60   \n",
       "\n",
       "     gross income  rating  \n",
       "995       17.2720     8.3  \n",
       "996       16.4295     4.2  \n",
       "997        2.7120     8.0  \n",
       "998        1.0660     5.9  \n",
       "999       34.3800     7.5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel = pd.read_excel(\"../Module 1/datasets/files/supermarket_demo.xlsx\", sheet_name = 'egypt', parse_dates=True)\n",
    "df_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the new type\n",
    "type(df_excel['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_excel.loc[0, 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_excel.iloc[0,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![excel file](https://s3-us-west-2.amazonaws.com/cdn.mychoicesoftware.com/blog/Excel_Meme.jpg)\n",
    "\n",
    "Excel files are very common, especially if some or all of the members in your team use it for their analyses and tend to share these with us periodically. If this is the case for you, this would mean that you would have to constantly read Excel files at work either with Excel or Google Sheets. But that is up until this point, of course. Fortunately, pandas provides a nice method to read in excel files, that is flexible enough to allow you te read in specific sheets at a time if that is what your use case requires.\n",
    "\n",
    "The pandas function, `pd.read_excel()`, just like `pd.read_csv()`, provides a plethora of options that you can choose from to tackle the complexity with which many Excel created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a regular file\n",
    "df_excel = pd.read_excel(\"../datasets/files/supermarket_demo.xlsx\")\n",
    "df_excel.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open up the supermarket dataset you will notice that it contains 2 sheets. pandas function `pd.read_excel()` by default reads in the first sheet it finds in a spreadsheet so in our case, that is the myanmar dataset as shown above. Let's now read in the egypt one with the help of the `sheet_name=` argument.\n",
    "\n",
    "Note that in the call below we also use the `parse_dates=True` argument instead of specifying the columns we want to parse, this is to tell pandas to infer which variables represent dates while it reads in the data. This method works well often but in most cases, it is better to be explicit about which variables you would like to parse as date type as opposed to leaving it to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel(\"../datasets/files/supermarket_demo.xlsx\", sheet_name='egypt', parse_dates=True)\n",
    "df_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new type\n",
    "type(df_excel['date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Find an Excel (or any spreadsheet) file in your computer that has data in a tabular format (i.e. a big square with rows and columns) and read it into your session with `pd.read_excel()`.\n",
    "\n",
    "2. If you can't find one to read in, create one with fake data and use that one insted. It does not need to have a lot of data in it. 10 rows and 5 columns would work fine.\n",
    "\n",
    "3. If you don't have Excel, you can create a spreadsheet using Google Sheets and download it as an Excel file.\n",
    "\n",
    "If neiether option above is feasible for you, please move on to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>947000.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>994000.0</td>\n",
       "      <td>1022000.0</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>1078000.0</td>\n",
       "      <td>1106000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1775680.0</td>\n",
       "      <td>1791000.0</td>\n",
       "      <td>1807106.0</td>\n",
       "      <td>1818117.0</td>\n",
       "      <td>1812771.0</td>\n",
       "      <td>1788196.0</td>\n",
       "      <td>1777557.0</td>\n",
       "      <td>1791003.0</td>\n",
       "      <td>1797085.0</td>\n",
       "      <td>1794248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>5315355.0</td>\n",
       "      <td>5393036.0</td>\n",
       "      <td>5473671.0</td>\n",
       "      <td>5556766.0</td>\n",
       "      <td>5641597.0</td>\n",
       "      <td>5727751.0</td>\n",
       "      <td>5816247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23154855.0</td>\n",
       "      <td>23807588.0</td>\n",
       "      <td>24473178.0</td>\n",
       "      <td>25147109.0</td>\n",
       "      <td>25823485.0</td>\n",
       "      <td>26497889.0</td>\n",
       "      <td>27168210.0</td>\n",
       "      <td>27834821.0</td>\n",
       "      <td>28498687.0</td>\n",
       "      <td>29161922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>17099840.0</td>\n",
       "      <td>17524533.0</td>\n",
       "      <td>17965725.0</td>\n",
       "      <td>18423161.0</td>\n",
       "      <td>18896307.0</td>\n",
       "      <td>19384841.0</td>\n",
       "      <td>19888250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51216964.0</td>\n",
       "      <td>52004172.0</td>\n",
       "      <td>52834005.0</td>\n",
       "      <td>53689236.0</td>\n",
       "      <td>54545991.0</td>\n",
       "      <td>55386367.0</td>\n",
       "      <td>56203654.0</td>\n",
       "      <td>57000451.0</td>\n",
       "      <td>57779622.0</td>\n",
       "      <td>58558270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3070776.0</td>\n",
       "      <td>3164329.0</td>\n",
       "      <td>3260650.0</td>\n",
       "      <td>3360104.0</td>\n",
       "      <td>3463213.0</td>\n",
       "      <td>3570464.0</td>\n",
       "      <td>3681955.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13605984.0</td>\n",
       "      <td>14023193.0</td>\n",
       "      <td>14465121.0</td>\n",
       "      <td>14926504.0</td>\n",
       "      <td>15399753.0</td>\n",
       "      <td>15879361.0</td>\n",
       "      <td>16363507.0</td>\n",
       "      <td>16853688.0</td>\n",
       "      <td>17351822.0</td>\n",
       "      <td>17861030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3776681.0</td>\n",
       "      <td>3905034.0</td>\n",
       "      <td>4039201.0</td>\n",
       "      <td>4178726.0</td>\n",
       "      <td>4322861.0</td>\n",
       "      <td>4471177.0</td>\n",
       "      <td>4623351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12697723.0</td>\n",
       "      <td>12894316.0</td>\n",
       "      <td>13115131.0</td>\n",
       "      <td>13350356.0</td>\n",
       "      <td>13586681.0</td>\n",
       "      <td>13814629.0</td>\n",
       "      <td>14030390.0</td>\n",
       "      <td>14236745.0</td>\n",
       "      <td>14439018.0</td>\n",
       "      <td>14645468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code     Indicator Name        1960        1961  \\\n",
       "259        Kosovo          XKX  Population, total    947000.0    966000.0   \n",
       "260   Yemen, Rep.          YEM  Population, total   5315355.0   5393036.0   \n",
       "261  South Africa          ZAF  Population, total  17099840.0  17524533.0   \n",
       "262        Zambia          ZMB  Population, total   3070776.0   3164329.0   \n",
       "263      Zimbabwe          ZWE  Population, total   3776681.0   3905034.0   \n",
       "\n",
       "           1962        1963        1964        1965        1966  ...  \\\n",
       "259    994000.0   1022000.0   1050000.0   1078000.0   1106000.0  ...   \n",
       "260   5473671.0   5556766.0   5641597.0   5727751.0   5816247.0  ...   \n",
       "261  17965725.0  18423161.0  18896307.0  19384841.0  19888250.0  ...   \n",
       "262   3260650.0   3360104.0   3463213.0   3570464.0   3681955.0  ...   \n",
       "263   4039201.0   4178726.0   4322861.0   4471177.0   4623351.0  ...   \n",
       "\n",
       "           2010        2011        2012        2013        2014        2015  \\\n",
       "259   1775680.0   1791000.0   1807106.0   1818117.0   1812771.0   1788196.0   \n",
       "260  23154855.0  23807588.0  24473178.0  25147109.0  25823485.0  26497889.0   \n",
       "261  51216964.0  52004172.0  52834005.0  53689236.0  54545991.0  55386367.0   \n",
       "262  13605984.0  14023193.0  14465121.0  14926504.0  15399753.0  15879361.0   \n",
       "263  12697723.0  12894316.0  13115131.0  13350356.0  13586681.0  13814629.0   \n",
       "\n",
       "           2016        2017        2018        2019  \n",
       "259   1777557.0   1791003.0   1797085.0   1794248.0  \n",
       "260  27168210.0  27834821.0  28498687.0  29161922.0  \n",
       "261  56203654.0  57000451.0  57779622.0  58558270.0  \n",
       "262  16363507.0  16853688.0  17351822.0  17861030.0  \n",
       "263  14030390.0  14236745.0  14439018.0  14645468.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_excel = pd.read_excel(\"../Module 1/datasets/files/WorldPopulation_excel.xlsx\")\n",
    "world_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>947000.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>994000.0</td>\n",
       "      <td>1022000.0</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>1078000.0</td>\n",
       "      <td>1106000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1775680.0</td>\n",
       "      <td>1791000.0</td>\n",
       "      <td>1807106.0</td>\n",
       "      <td>1818117.0</td>\n",
       "      <td>1812771.0</td>\n",
       "      <td>1788196.0</td>\n",
       "      <td>1777557.0</td>\n",
       "      <td>1791003.0</td>\n",
       "      <td>1797085.0</td>\n",
       "      <td>1794248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>5315355.0</td>\n",
       "      <td>5393036.0</td>\n",
       "      <td>5473671.0</td>\n",
       "      <td>5556766.0</td>\n",
       "      <td>5641597.0</td>\n",
       "      <td>5727751.0</td>\n",
       "      <td>5816247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23154855.0</td>\n",
       "      <td>23807588.0</td>\n",
       "      <td>24473178.0</td>\n",
       "      <td>25147109.0</td>\n",
       "      <td>25823485.0</td>\n",
       "      <td>26497889.0</td>\n",
       "      <td>27168210.0</td>\n",
       "      <td>27834821.0</td>\n",
       "      <td>28498687.0</td>\n",
       "      <td>29161922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>17099840.0</td>\n",
       "      <td>17524533.0</td>\n",
       "      <td>17965725.0</td>\n",
       "      <td>18423161.0</td>\n",
       "      <td>18896307.0</td>\n",
       "      <td>19384841.0</td>\n",
       "      <td>19888250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51216964.0</td>\n",
       "      <td>52004172.0</td>\n",
       "      <td>52834005.0</td>\n",
       "      <td>53689236.0</td>\n",
       "      <td>54545991.0</td>\n",
       "      <td>55386367.0</td>\n",
       "      <td>56203654.0</td>\n",
       "      <td>57000451.0</td>\n",
       "      <td>57779622.0</td>\n",
       "      <td>58558270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3070776.0</td>\n",
       "      <td>3164329.0</td>\n",
       "      <td>3260650.0</td>\n",
       "      <td>3360104.0</td>\n",
       "      <td>3463213.0</td>\n",
       "      <td>3570464.0</td>\n",
       "      <td>3681955.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13605984.0</td>\n",
       "      <td>14023193.0</td>\n",
       "      <td>14465121.0</td>\n",
       "      <td>14926504.0</td>\n",
       "      <td>15399753.0</td>\n",
       "      <td>15879361.0</td>\n",
       "      <td>16363507.0</td>\n",
       "      <td>16853688.0</td>\n",
       "      <td>17351822.0</td>\n",
       "      <td>17861030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>3776681.0</td>\n",
       "      <td>3905034.0</td>\n",
       "      <td>4039201.0</td>\n",
       "      <td>4178726.0</td>\n",
       "      <td>4322861.0</td>\n",
       "      <td>4471177.0</td>\n",
       "      <td>4623351.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12697723.0</td>\n",
       "      <td>12894316.0</td>\n",
       "      <td>13115131.0</td>\n",
       "      <td>13350356.0</td>\n",
       "      <td>13586681.0</td>\n",
       "      <td>13814629.0</td>\n",
       "      <td>14030390.0</td>\n",
       "      <td>14236745.0</td>\n",
       "      <td>14439018.0</td>\n",
       "      <td>14645468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code     Indicator Name        1960        1961  \\\n",
       "259        Kosovo          XKX  Population, total    947000.0    966000.0   \n",
       "260   Yemen, Rep.          YEM  Population, total   5315355.0   5393036.0   \n",
       "261  South Africa          ZAF  Population, total  17099840.0  17524533.0   \n",
       "262        Zambia          ZMB  Population, total   3070776.0   3164329.0   \n",
       "263      Zimbabwe          ZWE  Population, total   3776681.0   3905034.0   \n",
       "\n",
       "           1962        1963        1964        1965        1966  ...  \\\n",
       "259    994000.0   1022000.0   1050000.0   1078000.0   1106000.0  ...   \n",
       "260   5473671.0   5556766.0   5641597.0   5727751.0   5816247.0  ...   \n",
       "261  17965725.0  18423161.0  18896307.0  19384841.0  19888250.0  ...   \n",
       "262   3260650.0   3360104.0   3463213.0   3570464.0   3681955.0  ...   \n",
       "263   4039201.0   4178726.0   4322861.0   4471177.0   4623351.0  ...   \n",
       "\n",
       "           2010        2011        2012        2013        2014        2015  \\\n",
       "259   1775680.0   1791000.0   1807106.0   1818117.0   1812771.0   1788196.0   \n",
       "260  23154855.0  23807588.0  24473178.0  25147109.0  25823485.0  26497889.0   \n",
       "261  51216964.0  52004172.0  52834005.0  53689236.0  54545991.0  55386367.0   \n",
       "262  13605984.0  14023193.0  14465121.0  14926504.0  15399753.0  15879361.0   \n",
       "263  12697723.0  12894316.0  13115131.0  13350356.0  13586681.0  13814629.0   \n",
       "\n",
       "           2016        2017        2018        2019  \n",
       "259   1777557.0   1791003.0   1797085.0   1794248.0  \n",
       "260  27168210.0  27834821.0  28498687.0  29161922.0  \n",
       "261  56203654.0  57000451.0  57779622.0  58558270.0  \n",
       "262  16363507.0  16853688.0  17351822.0  17861030.0  \n",
       "263  14030390.0  14236745.0  14439018.0  14645468.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_excel = pd.read_excel(\"../Module 1/datasets/files/WorldPopulation_excel.xlsx\", sheet_name='WorldPopulation', parse_dates=True)\n",
    "world_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is DS_MSURFACEB2\n",
      " Volume Serial Number is 386D-B60D\n",
      "\n",
      " Directory of C:\\Users\\monch.mercader\\Python\\Data_Analytics\\Module 1\n",
      "\n",
      "21/11/2020  03:08 PM    <DIR>          .\n",
      "21/11/2020  03:08 PM    <DIR>          ..\n",
      "21/11/2020  03:00 PM    <DIR>          .ipynb_checkpoints\n",
      "31/10/2020  11:53 AM            12,944 00_CourseIntro.ipynb\n",
      "21/11/2020  08:42 AM           102,019 01_PythonIntro-1.ipynb\n",
      "07/11/2020  11:38 AM            23,312 02_ControlFlow.ipynb\n",
      "10/11/2020  07:59 PM            62,627 03_intermediate_python.ipynb\n",
      "10/11/2020  09:19 PM            73,045 04_numerical_computing.ipynb\n",
      "21/11/2020  10:27 AM           180,821 05_pandas.ipynb\n",
      "21/11/2020  03:00 PM            61,827 06_data_gathering.ipynb\n",
      "21/11/2020  03:08 PM            84,360 06_data_gathering_monch.ipynb\n",
      "21/11/2020  08:40 AM            38,227 07_data_cleaning.ipynb\n",
      "10/11/2020  06:09 PM            12,304 additional_numpy_challenges.ipynb\n",
      "21/11/2020  08:40 AM           301,193 csv_file.png\n",
      "21/11/2020  01:00 PM           535,387 dataframes.png\n",
      "21/11/2020  02:26 PM    <DIR>          datasets\n",
      "07/11/2020  02:37 PM            11,203 FunctionExercise.ipynb\n",
      "10/11/2020  07:57 PM           629,583 groceries.png\n",
      "07/11/2020  02:37 PM            12,923 IfElseElifExercise.ipynb\n",
      "07/11/2020  02:38 PM             8,203 LoopsExercise.ipynb\n",
      "10/11/2020  07:57 PM           220,299 matrix_x_1.jpeg\n",
      "10/11/2020  07:57 PM           235,319 matrix_x_2.jpeg\n",
      "10/11/2020  07:56 PM           233,018 matrix_x_3.jpeg\n",
      "07/11/2020  02:40 PM             3,747 ms_robot-1.py\n",
      "17/11/2020  09:45 PM             4,132 My_Own_lessons.ipynb\n",
      "07/11/2020  02:38 PM             5,819 NumpyExercises.ipynb\n",
      "10/11/2020  06:09 PM            15,106 numpy_challenge.ipynb\n",
      "07/11/2020  02:38 PM             6,874 PandasExercises_DA_Python.ipynb\n",
      "10/11/2020  07:56 PM           308,517 stacking-2.jpeg\n",
      "10/11/2020  08:00 PM    <DIR>          stacking.skt\n",
      "10/11/2020  07:56 PM         4,542,600 stacking.skt.zip\n",
      "21/11/2020  08:40 AM           246,968 table-1.png\n",
      "21/11/2020  11:49 AM               191 testing_csv.txt\n",
      "              28 File(s)      7,972,568 bytes\n",
      "               5 Dir(s)  136,797,106,176 bytes free\n"
     ]
    }
   ],
   "source": [
    "#Running terminal commands in here\n",
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HTML Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![html](https://media.giphy.com/media/l3vRfNA1p0rvhMSvS/giphy.gif)\n",
    "\n",
    "> \"Hypertext Markup Language (HTML) is the standard markup language for documents designed to be displayed in a web browser. It can be assisted by technologies such as Cascading Style Sheets (CSS) and scripting languages such as JavaScript.\" ~ [Wikipedia](https://en.wikipedia.org/wiki/HTML)\n",
    "\n",
    "pandas has, among many things, a function to allow us to read [HTML](https://html.spec.whatwg.org/) tables from a website. This function is `pd.read_html()`, and although it is not a full-fledge web scraping tool such as [Scrapy](https://scrapy.org/) or [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/). These last two libraries are very powerful web scraping tools that you are more than encouraged to explore on your own. Intermediate to complex web scraping requires a fair amount of knowledge on how the structure of a website works but I have no dobts that with a few hours of focused studying, a couple of projects later, or in the next couple of minutes, you might be well on your way to scraping your own data with ðŸ¼. ðŸ˜Ž\n",
    "\n",
    "Before we explore pandas method for web scraping, let's quickly define it:\n",
    "\n",
    "> **Web Scraping** refers to extracting data, structured or unstructured, from websites and making it useful for a variety of purposes, such as marketing analysis. Companies in the marketing arena use web scraping to colect comments about their products. Others, like Google, scrape the entire internet to rank websites given a criterion or search query. While web scraping might be limited in scope to a single website, like what a marketer might do, **web crawling** is the art of crawling over many different and/or nested websites on one try, or repeadately over time, like what Google does.\n",
    "\n",
    "We will be scraping the the International Foundation for Art Research website using the link below. An important thing to keep in mind is that, the pandas function `pd.read_html()` captures whichever tables it can find in the website provided and it then adds them to a list of dataframes where each  dataframe comes from a table. This means that you would have to first assign the list to a variable and then dump the table or tables you want into a combined dataframe.\n",
    "\n",
    "http://www.ifar.org/catalogues_raisonnes.php?alpha=&searchtype=artist&published=1&inPrep=1&artist=&author=\n",
    "\n",
    "How to check whether there is a table in a website or not. There are probably plenty of ways to check whether there is a table in a website or not, so here are two immediate ones.\n",
    "\n",
    "1. See if there is a table-like shape in the website that you are interested in. This table would ideally have information in a shape that would fit into a pandas dataframe. For example,\n",
    "![table](pictures/table.png)\n",
    "2. The second option is to navigate to the website you are interested in and \n",
    "\n",
    "If you have any issues with the `pd.read_html()` function, please check and see if you have the following packages installed and then try again.\n",
    "\n",
    "- `conda install lxml`\n",
    "- `pip install beautifulsoup4 html5lib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_html('http://www.ifar.org/catalogues_raisonnes.php?alpha=&searchtype=artist&published=1&inPrep=1&artist=&author=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n"
     ]
    }
   ],
   "source": [
    "print(type(data), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Birth Year</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Death Year</td>\n",
       "      <td>Death Place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachen, Hans von click to learn more</td>\n",
       "      <td>1552</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1615</td>\n",
       "      <td>Czech Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aalto, Alvar click to learn more</td>\n",
       "      <td>1898</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1976</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbati, Giuseppe click to learn more</td>\n",
       "      <td>1836</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1868</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdessemed, Adel click to learn more</td>\n",
       "      <td>1971</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0           1            2           3  \\\n",
       "0                                  Name  Birth Year  Birth Place  Death Year   \n",
       "1  Aachen, Hans von click to learn more        1552      Germany        1615   \n",
       "2      Aalto, Alvar click to learn more        1898      Finland        1976   \n",
       "3  Abbati, Giuseppe click to learn more        1836        Italy        1868   \n",
       "4  Abdessemed, Adel click to learn more        1971      Algeria         NaN   \n",
       "\n",
       "                4  \n",
       "0     Death Place  \n",
       "1  Czech Republic  \n",
       "2         Finland  \n",
       "3           Italy  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_html = data[0]\n",
    "df_html.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the column names are not where they should be. Let's fix that.\n",
    "\n",
    "We will take the column names from the first row, convert the selection to a regular Python list and then reasign these names to the column names of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Birth Year', 'Birth Place', 'Death Year', 'Death Place']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the first row out and make it a list\n",
    "col_names = df_html.iloc[0].tolist()\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Birth Place</th>\n",
       "      <th>Death Year</th>\n",
       "      <th>Death Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachen, Hans von click to learn more</td>\n",
       "      <td>1552</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1615</td>\n",
       "      <td>Czech Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aalto, Alvar click to learn more</td>\n",
       "      <td>1898</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1976</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbati, Giuseppe click to learn more</td>\n",
       "      <td>1836</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1868</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdessemed, Adel click to learn more</td>\n",
       "      <td>1971</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abelenda Zapata, Manuel click to learn more</td>\n",
       "      <td>1889</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1957</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name Birth Year Birth Place  \\\n",
       "1         Aachen, Hans von click to learn more       1552     Germany   \n",
       "2             Aalto, Alvar click to learn more       1898     Finland   \n",
       "3         Abbati, Giuseppe click to learn more       1836       Italy   \n",
       "4         Abdessemed, Adel click to learn more       1971     Algeria   \n",
       "5  Abelenda Zapata, Manuel click to learn more       1889       Spain   \n",
       "\n",
       "  Death Year     Death Place  \n",
       "1       1615  Czech Republic  \n",
       "2       1976         Finland  \n",
       "3       1868           Italy  \n",
       "4        NaN             NaN  \n",
       "5       1957           Spain  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reasign the names to the column names index\n",
    "df_html.columns = col_names\n",
    "\n",
    "# drop the first row of the dataframe\n",
    "df_html.drop(index=0, axis=0, inplace=True)\n",
    "df_html.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to find out what a list is\n",
    "type(df_html.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aachen, Hans von'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rstrip to take out a set of characters this is a test\n",
    "'Aachen, Hans von click to learn more'.replace(' click to learn more', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1           Aachen, Hans von\n",
       "2               Aalto, Alvar\n",
       "3           Abbati, Giuseppe\n",
       "4           Abdessemed, Adel\n",
       "5    Abelenda Zapata, Manuel\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the effect on the list\n",
    "df_html['Name'].str.replace(' click to learn more', '').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.strings.StringMethods at 0x249726ca340>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_html['Name'].str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Find a table to scrape in World Wide Web and read it in with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Star system</th>\n",
       "      <th>Controlling faction / Factions</th>\n",
       "      <th>Inf</th>\n",
       "      <th>Inf.1</th>\n",
       "      <th>Fac</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zeta Trianguli Australisâœ‚ï¸Ž</td>\n",
       "      <td>Zeta Trianguli Australis CorporationProgressiv...</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>53.2%</td>\n",
       "      <td>7</td>\n",
       "      <td>5.26 Ly</td>\n",
       "      <td>now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>Jiuyouâœ‚ï¸Ž</td>\n",
       "      <td>Coalition of LFT 1349Jiuyou AllianceProgressiv...</td>\n",
       "      <td>9.2%6.8%4.0%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>8</td>\n",
       "      <td>6.78 Ly</td>\n",
       "      <td>55 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LFT 1349âœ‚ï¸Ž</td>\n",
       "      <td>Arbor Caelum Internal Defense [Player]L 206-18...</td>\n",
       "      <td>7.2%4.9%</td>\n",
       "      <td>65.6%</td>\n",
       "      <td>7</td>\n",
       "      <td>7.37 Ly</td>\n",
       "      <td>51 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LHS 3167âœ‚ï¸Ž</td>\n",
       "      <td>United Systems Imperium [Player]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>7</td>\n",
       "      <td>8.03 Ly</td>\n",
       "      <td>5 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mariâœ‚ï¸Ž</td>\n",
       "      <td>People's Mari Revolutionary PartyProgressive P...</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>7</td>\n",
       "      <td>8.20 Ly</td>\n",
       "      <td>4 hours ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Power                 Star system  \\\n",
       "0   NaN  Zeta Trianguli Australisâœ‚ï¸Ž   \n",
       "1     C                    Jiuyouâœ‚ï¸Ž   \n",
       "2   NaN                  LFT 1349âœ‚ï¸Ž   \n",
       "3   NaN                  LHS 3167âœ‚ï¸Ž   \n",
       "4   NaN                      Mariâœ‚ï¸Ž   \n",
       "\n",
       "                      Controlling faction / Factions           Inf  Inf.1  \\\n",
       "0  Zeta Trianguli Australis CorporationProgressiv...         12.1%  53.2%   \n",
       "1  Coalition of LFT 1349Jiuyou AllianceProgressiv...  9.2%6.8%4.0%  57.5%   \n",
       "2  Arbor Caelum Internal Defense [Player]L 206-18...      7.2%4.9%  65.6%   \n",
       "3                   United Systems Imperium [Player]           NaN  43.8%   \n",
       "4  People's Mari Revolutionary PartyProgressive P...         13.7%  46.2%   \n",
       "\n",
       "   Fac     Dist         Updated  \n",
       "0    7  5.26 Ly             now  \n",
       "1    8  6.78 Ly  55 minutes ago  \n",
       "2    7  7.37 Ly  51 minutes ago  \n",
       "3    7  8.03 Ly     5 hours ago  \n",
       "4    7  8.20 Ly     4 hours ago  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inara = pd.read_html('https://inara.cz/galaxy-starsystem/11877/')\n",
    "print(type(inara), len(inara))\n",
    "\n",
    "type(inara[1])\n",
    "\n",
    "inara_cz = inara[1]\n",
    "inara_cz.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome Work!\n",
    "\n",
    "You are now ready to start cleaning and preparing datasets for analysis!\n",
    "\n",
    "![great_work](https://media.giphy.com/media/SWzVtsCPEPggXQsGoT/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
